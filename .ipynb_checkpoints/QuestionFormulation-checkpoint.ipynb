{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question formulation Notebook\n",
    "\n",
    "Use of toy dataset and notebook dependencies.\n",
    "\n",
    "### Notebook Set-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "app_name = \"w261-FinalProject\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the RDDs to see the form:\n",
    "trainRDD = sc.textFile(\"gs://w261_final-project_team13/train.txt\")\n",
    "testRDD = sc.textFile(\"gs://w261_final-project_team13/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16',\n",
       " '0\\t2\\t0\\t44\\t1\\t102\\t8\\t2\\t2\\t4\\t1\\t1\\t\\t4\\t68fd1e64\\tf0cf0024\\t6f67f7e5\\t41274cd7\\t25c83c98\\tfe6b92e5\\t922afcc0\\t0b153874\\ta73ee510\\t2b53e5fb\\t4f1b46f3\\t623049e6\\td7020589\\tb28479f6\\te6c5b5cd\\tc92f3b61\\t07c540c4\\tb04e4670\\t21ddcdc9\\t5840adea\\t60f6221e\\t\\t3a171ecb\\t43f13e8b\\te8b83407\\t731c3655']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t29\\t50\\t5\\t7260\\t437\\t1\\t4\\t14\\t\\t1\\t0\\t6\\t5a9ed9b0\\ta0e12995\\ta1e14474\\t08a40877\\t25c83c98\\t\\t964d1fdd\\t5b392875\\ta73ee510\\tde89c3d2\\t59cd5ae7\\t8d98db20\\t8b216f7b\\t1adce6ef\\t78c64a1d\\t3ecdadf7\\t3486227d\\t1616f155\\t21ddcdc9\\t5840adea\\t2c277e62\\t\\t423fab69\\t54c91918\\t9b3e8820\\te75c9ae9',\n",
       " '27\\t17\\t45\\t28\\t2\\t28\\t27\\t29\\t28\\t1\\t1\\t\\t23\\t68fd1e64\\t960c983b\\t9fbfbfd5\\t38c11726\\t25c83c98\\t7e0ccccf\\tfe06fd10\\t062b5529\\ta73ee510\\tca53fc84\\t67360210\\t895d8bbb\\t4f8e2224\\tf862f261\\tb4cc2435\\t4c0041e5\\te5ba7672\\tb4abdd09\\t21ddcdc9\\t5840adea\\t36a7ab86\\t\\t32c7478e\\t85e4d73f\\t010f6491\\tee63dd9b']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRDD.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both are tab-separated files, so we want to sample them into a single-node computation friendly file and get back to the local machines. For that we need to know how many observations we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset count: 45840617 observations.\n",
      "Test dataset count: 6042135 observations.\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset count:', trainRDD.count(), 'observations.')\n",
    "print('Test dataset count:', testRDD.count(), 'observations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on that we will take 0.3% of the dataset as sample, which will be roughly $45.840.617 \\cdot 0.0003 = 137.521$ observations and $10.38E3 \\cdot 0.0003 = 30$ MB, perfectly handle in a single node machine and still relevant. For the test dataset the same smaple ratio will be kept.\n",
    "\n",
    "Another point is that the text file do not have headers, and as we want to work with dataframes, we want to create a schema. To do that we may take a look at the `readme.txt` file supplied with the data:\n",
    "\n",
    "```\n",
    "====================================================\n",
    "\n",
    "Format:\n",
    "\n",
    "The columns are tab separeted with the following schema:\n",
    "<label> <integer feature 1> ... <integer feature 13> <categorical feature 1> ... <categorical feature 26>\n",
    "\n",
    "When a value is missing, the field is just empty.\n",
    "There is no label field in the test set.\n",
    "\n",
    "====================================================\n",
    "```\n",
    "\n",
    "Additionally we need to parse the data, going from lines of strings to integers and and strings. For that we can map the RDD after sampling and converting to the desired type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o32.partitions.\n: java.io.IOException: No FileSystem for scheme: gs\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0e3c9409cef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m               'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtoyTrainDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtoyTestDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \"\"\"\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             raise ValueError(\"The first row in RDD is empty, \"\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \"\"\"\n\u001b[0;32m-> 1393\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \"\"\"\n\u001b[1;32m   1344\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0mtotalParts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m         \u001b[0mpartsScanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mgetNumPartitions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o32.partitions.\n: java.io.IOException: No FileSystem for scheme: gs\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:258)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "labelsTrain = ['label','I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',\n",
    "               'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "               'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n",
    "\n",
    "labelsTest = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',\n",
    "              'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "              'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n",
    "\n",
    "toyTrainDF = trainRDD.sample(False, 0.003, 2019).map(lambda line: line.split('\\t')).toDF(labelsTrain)\n",
    "toyTestDF = testRDD.sample(False, 0.003, 2019).map(lambda line: line.split('\\t')).toDF(labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy train dataframe count: 137139\n",
      "Toy test dataframe count: 18181\n"
     ]
    }
   ],
   "source": [
    "# verifying the count:\n",
    "print('Toy train dataframe count:', toyTrainDF.count())\n",
    "print('Toy test dataframe count:', toyTestDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o219.parquet.\n: java.io.IOException: No FileSystem for scheme: gs\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:452)\n\tat org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:548)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:278)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:547)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3a7a36420979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now writing out toy datasets to be able to work on local machines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtoyTrainDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gs://w261_final-project_team13/toy_train.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtoyTestDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gs://w261_final-project_team13/toy_test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o219.parquet.\n: java.io.IOException: No FileSystem for scheme: gs\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:452)\n\tat org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:548)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:278)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:547)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "# Now writing out toy datasets to be able to work on local machines\n",
    "toyTrainDF.write.parquet(\"gs://w261_final-project_team13/toy_train.txt\")\n",
    "toyTestDF.write.parquet(\"gs://w261_final-project_team13/toy_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now running on the local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/notebooks/Assignments/FinalProject/W261-SP19-Team13-FinalProject\n"
     ]
    }
   ],
   "source": [
    "# copy the files to the local machine:\n",
    "!gsutil -m cp gs://w261_final-project_team13/toy_test.txt/* .data/toy_test.txt/\n",
    "!gsutil -m cp gs://w261_final-project_team13/toy_train.txt/* .data/toy_train.txt/\n",
    "gsutil cp gs://w261_final-project_team13/notebooks/* ./QuestionFormulation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the parquet files and print the first observations of each:\n",
    "toyTrainDF = spark.read.parquet(\"./data/toy_train.txt\")\n",
    "toyTestDF = spark.read.parquet(\"./data/toy_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label='0', I1='1', I2='2', I3='17', I4='3', I5='685', I6='16', I7='2', I8='3', I9='7', I10='1', I11='2', I12='1', I13='3', C1='05db9164', C2='38a947a1', C3='78c2dcf9', C4='041c8b35', C5='4cf72387', C6='6f6d9be8', C7='94aa68fb', C8='1f89b562', C9='a73ee510', C10='ac25feb9', C11='577aa337', C12='5b91fbfa', C13='f405e2e8', C14='07d13a8f', C15='a8041309', C16='15913bcf', C17='3486227d', C18='998b9a30', C19='', C20='', C21='3e2fae11', C22='', C23='32c7478e', C24='09a589c1', C25='', C26='')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyTrainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(I1='', I2='-1', I3='', I4='', I5='8124', I6='62', I7='5', I8='1', I9='37', I10='', I11='1', I12='', I13='', C1='05db9164', C2='08c2f5df', C3='dde182a0', C4='de1dc0c1', C5='25c83c98', C6='fbad5c96', C7='ad3508b1', C8='0b153874', C9='a73ee510', C10='965e1030', C11='ad757a5a', C12='7a27d4e1', C13='93b18cb5', C14='1adce6ef', C15='a43baafd', C16='84534f54', C17='e5ba7672', C18='29b0e3e5', C19='', C20='', C21='2b81e06c', C22='c9d4222a', C23='423fab69', C24='2f647dfe', C25='', C26='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyTestDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all features are strings. We want to cast the `label` feature to _Boolean_ and the `I1` to `I13` features to _integers_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyTrainDF = toyTrainDF.withColumn('label', toyTrainDF.label.cast('Boolean'))\n",
    "\n",
    "intColumns = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13']\n",
    "\n",
    "# convert to number. Cast to float to be able to use NaN:\n",
    "for column in intColumns: \n",
    "    toyTrainDF = toyTrainDF.withColumn(column, F.when(toyTrainDF[column] != \"\", toyTrainDF[column].cast('float')).otherwise(float('NaN')))\n",
    "    toyTestDF = toyTestDF.withColumn(column, F.when(toyTestDF[column] != \"\", toyTestDF[column].cast('float')).otherwise(float('NaN')))\n",
    "    \n",
    "strColumns = ['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "              'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n",
    "for column in strColumns:\n",
    "    toyTrainDF = toyTrainDF.withColumn(column, F.when(toyTrainDF[column] != \"\", toyTrainDF[column]).otherwise(float('NaN')))\n",
    "    toyTestDF = toyTestDF.withColumn(column, F.when(toyTestDF[column] != \"\", toyTestDF[column]).otherwise(float('NaN')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=False, I1=1.0, I2=2.0, I3=17.0, I4=3.0, I5=685.0, I6=16.0, I7=2.0, I8=3.0, I9=7.0, I10=1.0, I11=2.0, I12=1.0, I13=3.0, C1='05db9164', C2='38a947a1', C3='78c2dcf9', C4='041c8b35', C5='4cf72387', C6='6f6d9be8', C7='94aa68fb', C8='1f89b562', C9='a73ee510', C10='ac25feb9', C11='577aa337', C12='5b91fbfa', C13='f405e2e8', C14='07d13a8f', C15='a8041309', C16='15913bcf', C17='3486227d', C18='998b9a30', C19='NaN', C20='NaN', C21='3e2fae11', C22='NaN', C23='32c7478e', C24='09a589c1', C25='NaN', C26='NaN')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyTrainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(I1=nan, I2=-1.0, I3=nan, I4=nan, I5=8124.0, I6=62.0, I7=5.0, I8=1.0, I9=37.0, I10=nan, I11=1.0, I12=nan, I13=nan, C1='05db9164', C2='08c2f5df', C3='dde182a0', C4='de1dc0c1', C5='25c83c98', C6='fbad5c96', C7='ad3508b1', C8='0b153874', C9='a73ee510', C10='965e1030', C11='ad757a5a', C12='7a27d4e1', C13='93b18cb5', C14='1adce6ef', C15='a43baafd', C16='84534f54', C17='e5ba7672', C18='29b0e3e5', C19='NaN', C20='NaN', C21='2b81e06c', C22='c9d4222a', C23='423fab69', C24='2f647dfe', C25='NaN', C26='NaN')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyTestDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start analyzing the data to understand which features are more likely to contribute to a model and which are more likely to bias our model (due to a high number of `None` values or that need normalization, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "As we are not sure which any of the variables means, we need to take a look on each and every one trying to understand if it is valuable for the click-through rate. We can check what is the overall rate for the whole dataset and as a baseline and see which are better than the baseline and which are worst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall click-through rate: 25.68%\n",
      "Overall click-through count: 0. This represents 0.00% of the dataset.\n"
     ]
    }
   ],
   "source": [
    "# check the overall rate:\n",
    "totalCount = toyTrainDF.count()\n",
    "truePerc = toyTrainDF.filter(toyTrainDF.label == True).count()/totalCount\n",
    "print('Overall click-through rate: {0:3.2f}%'.format(truePerc*100))\n",
    "\n",
    "# none count in label feature:\n",
    "noneCount = toyTrainDF.filter(toyTrainDF.label == float('NaN')).count()\n",
    "print('Overall click-through count: {0:d}. This represents {1:3.2f}% of the dataset.'.format(noneCount,noneCount/totalCount*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have 39 features, it is a good idea to verify each one for its effectiveness, checking count of values, distributions, etc. For the numeric variables we have the describe function, but we also wants to verify None value count and the most frequent variables count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descNumEDA(dataframe, column, totalCount=0, nanThreshold=0.5):\n",
    "    \"\"\"\n",
    "    Function that prints an analysis of column from the given dataframe. Retuns None.\n",
    "    Args:\n",
    "        dataframe    - input dataframe\n",
    "        column       - string with a dataframe column.\n",
    "        totalCount   - optional. Number of rows in the dataframe (if defined avoid recalculation).\n",
    "        nanThreshold - optional. Percentage allowed of NaN values in the column.\n",
    "    Returns:\n",
    "        Column       - name of the column if the column have more NaN if it represents more \n",
    "                       than nanThreshold ratio.\n",
    "    Output:\n",
    "        NaN Count    - number for NaN values in % of the row count of the dataframe.\n",
    "        Mean         - mean of the valid entries\n",
    "        StdDev       - standard deviation of the valid entries\n",
    "        Max          - maximum value of the valid entries\n",
    "        3rd Quartile - 75% quartile od the \n",
    "        Median       - 50% quartile of the valid entries\n",
    "        1st Quartile - 25% of the valid entries\n",
    "        Min          - minimum value of the valid entries\n",
    "        Most Freq    - number of values for the 5 most frequent values\n",
    "        \n",
    "    \"\"\"\n",
    "    if totalCount == 0:\n",
    "        totalCount = dataframe.count()\n",
    "    \n",
    "    pandCol = dataframe.select(column).toPandas()[column]\n",
    "    freqNumbers = dict(pandCol.value_counts(normalize=True).head(5))\n",
    "    \n",
    "    nanCount = dataframe.filter(F.isnan(dataframe[column])).count()\n",
    "    \n",
    "    validCount = totalCount - nanCount\n",
    "    \n",
    "    print('+'+13*'-'+'+'+30*'-'+'+')\n",
    "    print('|Feature: {:^4}'.format(column)+'|{:>22}{:>6.2f}% |'.format('Null Count: ', nanCount/totalCount*100))\n",
    "    print('+'+13*'-'+'+'+30*'-'+'+')\n",
    "    print('|{:>12} |{:>29.2f} |'.format('Mean', pandCol.mean()))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('StdDev', pandCol.std()))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('Maximum', pandCol.max()))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('3rd Quartile', pandCol.quantile(q=0.75)))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('Median', pandCol.quantile(q=0.5)))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('1st Quartile', pandCol.quantile(q=0.25)))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('Minimum', pandCol.min()))\n",
    "    print('|{:>12} |{:>29.2f} |'.format('Unique Val.', pandCol.nunique()))\n",
    "    print('+'+13*'-'+'+'+30*'-'+'+')\n",
    "    print('| Most Freq.: {:>30} |'.format(str(list(freqNumbers.keys()))))\n",
    "    print('+'+13*'-'+'+'+30*'-'+'+')\n",
    "    for item in freqNumbers:\n",
    "        print('|{:>12} |{:>28.2f}% |'.format(item, freqNumbers[item]*100))\n",
    "    print('+'+13*'-'+'+'+30*'-'+'+\\n')\n",
    "    \n",
    "    if nanCount/totalCount*100 > nanTreshold*100:\n",
    "        return column\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------------+\n",
      "|Feature:  I1 |          Null Count:  45.09% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                         3.52 |\n",
      "|      StdDev |                         9.13 |\n",
      "|     Maximum |                       425.00 |\n",
      "|3rd Quartile |                         3.00 |\n",
      "|      Median |                         1.00 |\n",
      "|1st Quartile |                         0.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       156.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [0.0, 1.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                       42.56% |\n",
      "|         1.0 |                       17.66% |\n",
      "|         2.0 |                        9.69% |\n",
      "|         3.0 |                        5.93% |\n",
      "|         4.0 |                        4.40% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I2 |          Null Count:   0.00% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                       105.90 |\n",
      "|      StdDev |                       388.57 |\n",
      "|     Maximum |                     10255.00 |\n",
      "|3rd Quartile |                        35.00 |\n",
      "|      Median |                         3.00 |\n",
      "|1st Quartile |                         0.00 |\n",
      "|     Minimum |                        -2.00 |\n",
      "| Unique Val. |                      2991.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:     [0.0, 1.0, -1.0, 2.0, 3.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                       17.36% |\n",
      "|         1.0 |                       15.45% |\n",
      "|        -1.0 |                       10.20% |\n",
      "|         2.0 |                        5.65% |\n",
      "|         3.0 |                        3.05% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I3 |          Null Count:  21.34% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                        26.77 |\n",
      "|      StdDev |                       410.12 |\n",
      "|     Maximum |                     65535.00 |\n",
      "|3rd Quartile |                        17.00 |\n",
      "|      Median |                         6.00 |\n",
      "|1st Quartile |                         2.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       739.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [1.0, 2.0, 3.0, 4.0, 5.0] |\n",
      "+-------------+------------------------------+\n",
      "|         1.0 |                       16.06% |\n",
      "|         2.0 |                       10.70% |\n",
      "|         3.0 |                        8.10% |\n",
      "|         4.0 |                        6.53% |\n",
      "|         5.0 |                        5.30% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I4 |          Null Count:  21.45% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                         7.34 |\n",
      "|      StdDev |                         8.83 |\n",
      "|     Maximum |                       349.00 |\n",
      "|3rd Quartile |                        10.00 |\n",
      "|      Median |                         4.00 |\n",
      "|1st Quartile |                         2.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       105.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [1.0, 2.0, 3.0, 4.0, 5.0] |\n",
      "+-------------+------------------------------+\n",
      "|         1.0 |                       16.59% |\n",
      "|         2.0 |                       12.84% |\n",
      "|         3.0 |                        9.77% |\n",
      "|         4.0 |                        7.84% |\n",
      "|         5.0 |                        6.29% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I5 |          Null Count:   2.63% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                     18508.84 |\n",
      "|      StdDev |                     69488.10 |\n",
      "|     Maximum |                   2071071.00 |\n",
      "|3rd Quartile |                     10081.00 |\n",
      "|      Median |                      2796.00 |\n",
      "|1st Quartile |                       329.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                     28379.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [1.0, 0.0, 2.0, 4.0, 5.0] |\n",
      "+-------------+------------------------------+\n",
      "|         1.0 |                        2.33% |\n",
      "|         0.0 |                        1.90% |\n",
      "|         2.0 |                        1.47% |\n",
      "|         4.0 |                        1.18% |\n",
      "|         5.0 |                        0.93% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I6 |          Null Count:  22.27% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                       118.60 |\n",
      "|      StdDev |                       485.87 |\n",
      "|     Maximum |                    111105.00 |\n",
      "|3rd Quartile |                       103.00 |\n",
      "|      Median |                        32.00 |\n",
      "|1st Quartile |                         8.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                      2098.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [0.0, 1.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                        6.50% |\n",
      "|         1.0 |                        3.54% |\n",
      "|         2.0 |                        3.10% |\n",
      "|         3.0 |                        2.67% |\n",
      "|         4.0 |                        2.42% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I7 |          Null Count:   4.28% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                        16.44 |\n",
      "|      StdDev |                        64.90 |\n",
      "|     Maximum |                      6498.00 |\n",
      "|3rd Quartile |                        12.00 |\n",
      "|      Median |                         3.00 |\n",
      "|1st Quartile |                         1.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       732.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [0.0, 1.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                       22.52% |\n",
      "|         1.0 |                       13.51% |\n",
      "|         2.0 |                        8.99% |\n",
      "|         3.0 |                        6.24% |\n",
      "|         4.0 |                        5.20% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I8 |          Null Count:   0.05% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                        12.50 |\n",
      "|      StdDev |                        14.73 |\n",
      "|     Maximum |                      1689.00 |\n",
      "|3rd Quartile |                        19.00 |\n",
      "|      Median |                         7.00 |\n",
      "|1st Quartile |                         2.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       124.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [0.0, 1.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                       11.40% |\n",
      "|         1.0 |                        8.28% |\n",
      "|         2.0 |                        6.99% |\n",
      "|         3.0 |                        5.85% |\n",
      "|         4.0 |                        5.33% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature:  I9 |          Null Count:   4.28% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                       107.03 |\n",
      "|      StdDev |                       223.71 |\n",
      "|     Maximum |                      9465.00 |\n",
      "|3rd Quartile |                       110.00 |\n",
      "|      Median |                        39.00 |\n",
      "|1st Quartile |                        10.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                      1822.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [1.0, 0.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         1.0 |                        3.94% |\n",
      "|         0.0 |                        3.22% |\n",
      "|         2.0 |                        3.16% |\n",
      "|         3.0 |                        2.61% |\n",
      "|         4.0 |                        2.30% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature: I10 |          Null Count:  45.09% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                         0.62 |\n",
      "|      StdDev |                         0.68 |\n",
      "|     Maximum |                         7.00 |\n",
      "|3rd Quartile |                         1.00 |\n",
      "|      Median |                         1.00 |\n",
      "|1st Quartile |                         0.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                         8.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [0.0, 1.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                       47.85% |\n",
      "|         1.0 |                       44.40% |\n",
      "|         2.0 |                        6.40% |\n",
      "|         3.0 |                        1.07% |\n",
      "|         4.0 |                        0.22% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature: I11 |          Null Count:   4.28% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                         2.74 |\n",
      "|      StdDev |                         5.23 |\n",
      "|     Maximum |                       123.00 |\n",
      "|3rd Quartile |                         3.00 |\n",
      "|      Median |                         1.00 |\n",
      "|1st Quartile |                         1.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       100.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [1.0, 0.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         1.0 |                       34.84% |\n",
      "|         0.0 |                       23.37% |\n",
      "|         2.0 |                       14.43% |\n",
      "|         3.0 |                        7.61% |\n",
      "|         4.0 |                        4.78% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature: I12 |          Null Count:  76.52% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                         1.00 |\n",
      "|      StdDev |                         4.91 |\n",
      "|     Maximum |                       193.00 |\n",
      "|3rd Quartile |                         1.00 |\n",
      "|      Median |                         0.00 |\n",
      "|1st Quartile |                         0.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                        88.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [0.0, 1.0, 2.0, 3.0, 4.0] |\n",
      "+-------------+------------------------------+\n",
      "|         0.0 |                       74.27% |\n",
      "|         1.0 |                       15.60% |\n",
      "|         2.0 |                        3.36% |\n",
      "|         3.0 |                        1.53% |\n",
      "|         4.0 |                        0.92% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "+-------------+------------------------------+\n",
      "|Feature: I13 |          Null Count:  21.45% |\n",
      "+-------------+------------------------------+\n",
      "|        Mean |                         8.21 |\n",
      "|      StdDev |                        12.75 |\n",
      "|     Maximum |                      1574.00 |\n",
      "|3rd Quartile |                        10.00 |\n",
      "|      Median |                         4.00 |\n",
      "|1st Quartile |                         2.00 |\n",
      "|     Minimum |                         0.00 |\n",
      "| Unique Val. |                       191.00 |\n",
      "+-------------+------------------------------+\n",
      "| Most Freq.:      [1.0, 2.0, 3.0, 4.0, 0.0] |\n",
      "+-------------+------------------------------+\n",
      "|         1.0 |                       16.16% |\n",
      "|         2.0 |                       12.49% |\n",
      "|         3.0 |                        9.38% |\n",
      "|         4.0 |                        7.56% |\n",
      "|         0.0 |                        6.34% |\n",
      "+-------------+------------------------------+\n",
      "\n",
      "List of feature with more than 40.00% NaN ratio: ['I1', 'I10', 'I12']\n"
     ]
    }
   ],
   "source": [
    "badFeatures = []\n",
    "nanTreshold = 0.4\n",
    "\n",
    "for item in intColumns:\n",
    "    badFeatures.append(descNumEDA(toyTrainDF, item, totalCount, nanTreshold))\n",
    "\n",
    "badFeatures = list(filter(None,badFeatures))\n",
    "print('List of feature with more than {:4.2f}% NaN ratio: {}'.format(nanTreshold*100, badFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we see that most features are right skewed, with most of its values near zero. Additionally we were able to identify features with a lot of `NaN` values. This analisys will be usefull in the future when deciding which algorithm we want to use.\n",
    "\n",
    "Now, doing a similar analisys for the categorical values, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descCatEDA(dataframe, column, totalCount=0, nanThreshold=0.5):\n",
    "    \"\"\"\n",
    "    Function that prints an analysis of column from the given dataframe. Retuns None.\n",
    "    Args:\n",
    "        dataframe    - input dataframe\n",
    "        column       - string with a dataframe column.\n",
    "        totalCount   - optional. Number of rows in the dataframe (if defined avoid recalculation).\n",
    "        nanThreshold - optional. Percentage allowed of NaN values in the column.\n",
    "    Returns:\n",
    "        Column       - name of the column if the column have more NaN if it represents more \n",
    "                       than nanThreshold ratio.\n",
    "    Output:\n",
    "        NaN Count    - number for NaN values in % of the row count of the dataframe.\n",
    "        Most Freq    - number of values for the 5 most frequent values (discarding NaN).\n",
    "        \n",
    "    \"\"\"\n",
    "    if totalCount == 0:\n",
    "        totalCount = dataframe.count()\n",
    "    \n",
    "    pandCol = dataframe.select(column).toPandas()[column]\n",
    "    freqNumbers = dict(pandCol.value_counts(normalize=True).head(5))\n",
    "    \n",
    "    nanCount = dataframe.filter(F.isnan(dataframe[column])).count()\n",
    "    \n",
    "    validCount = totalCount - nanCount\n",
    "    \n",
    "    print('+'+13*'-'+'+'+22*'-'+'+')\n",
    "    print('|Feature: {:^4}'.format(column)+'|{:>14}{:>6.2f}% |'.format('Null Count: ', nanCount/totalCount*100))\n",
    "    print('+'+13*'-'+'+'+22*'-'+'+')\n",
    "    print('| Unique Values: {:>19} |'.format(pandCol.nunique()))\n",
    "    print('+'+13*'-'+'+'+22*'-'+'+')\n",
    "    for item in freqNumbers:\n",
    "        print('|{:>12} |{:>20.2f}% |'.format(item, freqNumbers[item]*100))\n",
    "    print('+'+13*'-'+'+'+22*'-'+'+\\n')\n",
    "    \n",
    "    if nanCount/totalCount*100 > nanTreshold*100:\n",
    "        return column\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n",
      "|Feature:  C1 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                 616 |\n",
      "+-------------+----------------------+\n",
      "|    05db9164 |               50.04% |\n",
      "|    68fd1e64 |               16.78% |\n",
      "|    5a9ed9b0 |                8.39% |\n",
      "|    8cf07265 |                4.97% |\n",
      "|    be589b51 |                3.28% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C2 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                 528 |\n",
      "+-------------+----------------------+\n",
      "|    38a947a1 |               11.35% |\n",
      "|    207b2d81 |                4.29% |\n",
      "|    38d50e09 |                3.80% |\n",
      "|    1cfdf714 |                3.67% |\n",
      "|    287130e0 |                3.54% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C3 |  Null Count:   3.45% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               61764 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |                3.45% |\n",
      "|    d032c263 |                2.53% |\n",
      "|    02cf9876 |                1.05% |\n",
      "|    9143c832 |                1.01% |\n",
      "|    aa8c1539 |                0.95% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C4 |  Null Count:   3.45% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               32223 |\n",
      "+-------------+----------------------+\n",
      "|    c18be181 |                3.58% |\n",
      "|         NaN |                3.45% |\n",
      "|    29998ed1 |                2.24% |\n",
      "|    d16679b9 |                2.14% |\n",
      "|    85dd697c |                1.92% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C5 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                 154 |\n",
      "+-------------+----------------------+\n",
      "|    25c83c98 |               67.42% |\n",
      "|    4cf72387 |               15.44% |\n",
      "|    43b19349 |                6.28% |\n",
      "|    384874ce |                3.33% |\n",
      "|    30903e74 |                1.84% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C6 |  Null Count:  12.18% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                  12 |\n",
      "+-------------+----------------------+\n",
      "|    7e0ccccf |               39.62% |\n",
      "|    fbad5c96 |               21.88% |\n",
      "|    fe6b92e5 |               18.57% |\n",
      "|         NaN |               12.18% |\n",
      "|    13718bbd |                3.14% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C7 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                8634 |\n",
      "+-------------+----------------------+\n",
      "|    1c86e0eb |                2.12% |\n",
      "|    dc7659bd |                1.31% |\n",
      "|    7195046d |                0.89% |\n",
      "|    468a0854 |                0.75% |\n",
      "|    5e64ce5f |                0.72% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C8 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                 292 |\n",
      "+-------------+----------------------+\n",
      "|    0b153874 |               59.49% |\n",
      "|    5b392875 |               16.54% |\n",
      "|    1f89b562 |                7.42% |\n",
      "|    37e4aa92 |                4.17% |\n",
      "|    062b5529 |                2.53% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature:  C9 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                   3 |\n",
      "+-------------+----------------------+\n",
      "|    a73ee510 |               90.00% |\n",
      "|    7cc72ec2 |                9.99% |\n",
      "|    a18233ea |                0.02% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C10 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               13982 |\n",
      "+-------------+----------------------+\n",
      "|    3b08e48b |               22.21% |\n",
      "|    efea433b |                1.49% |\n",
      "|    fbbf2c95 |                0.75% |\n",
      "|    fa7d0797 |                0.59% |\n",
      "|    03e48276 |                0.55% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C11 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                4087 |\n",
      "+-------------+----------------------+\n",
      "|    755e4a50 |                3.20% |\n",
      "|    e51ddf94 |                2.11% |\n",
      "|    7f8ffe57 |                1.55% |\n",
      "|    4d8549da |                1.29% |\n",
      "|    8b94178b |                1.07% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C12 |  Null Count:   3.45% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               56397 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |                3.45% |\n",
      "|    dfbb09fb |                2.53% |\n",
      "|    6aaba33c |                2.24% |\n",
      "|    8fe001f4 |                1.05% |\n",
      "|    ae1bb660 |                1.01% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C13 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                2944 |\n",
      "+-------------+----------------------+\n",
      "|    5978055e |                3.20% |\n",
      "|    3516f6e6 |                2.36% |\n",
      "|    46f42a63 |                1.68% |\n",
      "|    025225f2 |                1.39% |\n",
      "|    1aa94af3 |                1.30% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C14 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                  26 |\n",
      "+-------------+----------------------+\n",
      "|    b28479f6 |               34.91% |\n",
      "|    07d13a8f |               34.17% |\n",
      "|    1adce6ef |               15.47% |\n",
      "|    64c94865 |                4.48% |\n",
      "|    cfef1c29 |                3.02% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C15 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                5897 |\n",
      "+-------------+----------------------+\n",
      "|    2d0bb053 |                1.55% |\n",
      "|    d345b1a0 |                1.06% |\n",
      "|    3628a186 |                0.94% |\n",
      "|    10040656 |                0.88% |\n",
      "|    10935a85 |                0.80% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C16 |  Null Count:   3.45% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               46382 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |                3.45% |\n",
      "|    84898b2a |                2.53% |\n",
      "|    b041b04a |                2.24% |\n",
      "|    36103458 |                1.05% |\n",
      "|    bad5ee18 |                1.01% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C17 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                  10 |\n",
      "+-------------+----------------------+\n",
      "|    e5ba7672 |               46.02% |\n",
      "|    07c540c4 |               13.16% |\n",
      "|    d4bb7bd8 |               11.32% |\n",
      "|    3486227d |                8.45% |\n",
      "|    776ce399 |                5.29% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C18 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                2827 |\n",
      "+-------------+----------------------+\n",
      "|    e88ffc9d |                3.20% |\n",
      "|    891589e7 |                2.83% |\n",
      "|    2804effd |                2.68% |\n",
      "|    c21c3e4c |                2.34% |\n",
      "|    5aed7436 |                2.09% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C19 |  Null Count:  44.18% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                1342 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |               44.18% |\n",
      "|    21ddcdc9 |               34.42% |\n",
      "|    55dd3565 |                1.92% |\n",
      "|    5b885066 |                0.77% |\n",
      "|    9437f62f |                0.76% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C20 |  Null Count:  44.18% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                   4 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |               44.18% |\n",
      "|    b1252a9d |               18.99% |\n",
      "|    5840adea |               18.55% |\n",
      "|    a458ea53 |               18.28% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C21 |  Null Count:   3.45% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               52250 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |                3.45% |\n",
      "|    0014c32a |                2.53% |\n",
      "|    723b4dfd |                2.24% |\n",
      "|    e587c466 |                1.05% |\n",
      "|    0429f84b |                1.01% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C22 |  Null Count:  76.13% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                  13 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |               76.13% |\n",
      "|    ad3062eb |               13.59% |\n",
      "|    c9d4222a |                8.55% |\n",
      "|    78e2e389 |                0.76% |\n",
      "|    8ec974f4 |                0.53% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C23 |  Null Count:   0.00% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                  14 |\n",
      "+-------------+----------------------+\n",
      "|    32c7478e |               43.74% |\n",
      "|    3a171ecb |               19.99% |\n",
      "|    423fab69 |               12.09% |\n",
      "|    bcdee96c |                6.96% |\n",
      "|    be7c41b4 |                5.76% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C24 |  Null Count:   3.45% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               14596 |\n",
      "+-------------+----------------------+\n",
      "|    3fdb382b |                5.29% |\n",
      "|    b34f3128 |                4.79% |\n",
      "|    3b183c5c |                4.58% |\n",
      "|    1793a828 |                4.27% |\n",
      "|         NaN |                3.45% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C25 |  Null Count:  44.18% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:                  55 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |               44.18% |\n",
      "|    001f3601 |               14.23% |\n",
      "|    e8b83407 |               10.76% |\n",
      "|    ea9a246c |                8.03% |\n",
      "|    cb079c2d |                3.98% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|Feature: C26 |  Null Count:  44.18% |\n",
      "+-------------+----------------------+\n",
      "| Unique Values:               11139 |\n",
      "+-------------+----------------------+\n",
      "|         NaN |               44.18% |\n",
      "|    49d68486 |                4.15% |\n",
      "|    c84c4aec |                1.82% |\n",
      "|    2fede552 |                1.60% |\n",
      "|    c27f155b |                1.49% |\n",
      "+-------------+----------------------+\n",
      "\n",
      "List of feature with more than 40.00% NaN ratio: ['I1', 'I10', 'I12', 'C19', 'C20', 'C22', 'C25', 'C26']\n"
     ]
    }
   ],
   "source": [
    "for item in strColumns:\n",
    "    badFeatures.append(descCatEDA(toyTrainDF, item, totalCount, nanTreshold))\n",
    "\n",
    "badFeatures = list(filter(None,badFeatures))\n",
    "print('List of feature with more than {:4.2f}% NaN ratio: {}'.format(nanTreshold*100, badFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61832"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyTrainDF.filter(F.isnan(toyTrainDF['I1'])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     (avg(I2) + 5)|\n",
      "+------------------+\n",
      "|110.89924820802251|\n",
      "+------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "F.mean(toyTrainDF.filter(F.isnan(toyTrainDF['I1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(I1)=nan)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyTrainDF.agg(F.avg(toyTrainDF['I1'])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 32053, 1.0: 13296, 2.0: 7299, 3.0: 4467, 4.0: 3310}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  dict(toyTrainDF.select('I1').toPandas()['I1'].value_counts().head(5))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0.0, 1.0, 2.0, 3.0, 4.0])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
